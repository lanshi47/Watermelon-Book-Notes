\section{绪论}
\subsection{引言}
略
\subsection{基本术语}
\begin{enumerate}[label=(\roman*)]
    \item 样本/示例-sample/instance
    \item 训练集-training data
    \item 测试集-testing data
    \item 标记-label 
    \item 样例-example:拥有label的instance
    \item 泛化-generalization
\end{enumerate}
\subsection{假设空间}
\subsubsection{科学推理}
\begin{itemize}
    \item 归纳--induction
    从具体的事实归结出一般性规律
    \item 演绎--deduction
    从基础原理推演出具体状况
\end{itemize}
\subsubsection{归纳学习--inductive learning}
\begin{itemize}
    \item 广义归纳学习
    \item 狭义归纳学习--概念学习
    eg:布尔概念学习
\end{itemize}
\subsubsection{版本空间--version space}
即存在着一个与训练集一致的"假设集合"
\subsection{归纳偏好}
有多个与训练集一致的假设,但测试新样本时有不同的输出结果,那么采用哪种模型(假设)?
\subsubsection{"奥卡姆剃刀"原则}
若有多个假设与观察一致,则选最简单的那个.
利用什么原则,取决于算法能否获得更好的性能,泛化能力是否更强
\subsubsection{NFL(No Free Lunch Theorem)定理--"没有免费的午餐"定理}




